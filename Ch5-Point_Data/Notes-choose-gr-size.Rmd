---
title: "Notes on the choice of group size"
author: "Yifan Li"
date: "21/06/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation 

```{r}
source("JointWork-GframeARCH.R")
source("GframeStatsPoint.R")
source("functions-choose-gr-size.R")
```

```{r}
library(quantmod)
library(reshape2)
library(ggplot2)
```


```{r}
#load the real-world data: S&P500
#with typical volatility uncertainty 
startdate <- "1990-01-03" #avoid the holidays (a minor issue here)
#enddate <- "2019-01-01"
enddate <- "2021-05-21" #avoid the holidays
#30 years 
scale.f <- function(x) x*10 
#try higher frequency to have more points
#North American Market: S&P500
#getSymbols("^GSPC", from=startdate, to=enddate, by=60*60)
getSymbols("^GSPC", from=startdate, to=enddate)
#head(GSPC)
gspc <- GSPC[,"GSPC.Close"] #gspc <- Cl(GSPC)
logReturn.gspc.old <- diff(log(gspc))
logReturn.gspc <- logReturn.gspc.old[-1]
#plot(logReturn.gspc)
plot(logReturn.gspc["2018/2021"])
logReturn.gspc.num <- as.numeric(logReturn.gspc)
any(is.na(gspc))
logReturn.gspc.sc <- scale.f(logReturn.gspc) #after scaling
logReturn.gspc.num.sc <- as.numeric(logReturn.gspc.sc)
```

```{r}
#Chinese Market: HSI
getSymbols("^HSI", from=startdate, to=enddate)
hsi <- HSI[,"HSI.Close"] #gspc <- Cl(GSPC)
#there are NAs in hsi,
na.ind <- which(is.na(hsi))
#any(is.na(hsi))
#hsi[na.ind]
#we can see that the missing values are from the holidays
#so far we simply remove the missing values
hsi.new <- na.omit(hsi)
#we may fill the NAs by interpolation in the future
#to compare with other markets (to have the same dimension)
logReturn.hsi.old <- diff(log(hsi.new))
logReturn.hsi <- logReturn.hsi.old[-1]
logReturn.hsi.num <- as.numeric(logReturn.hsi)
logReturn.hsi.sc <- scale.f(logReturn.hsi)
logReturn.hsi.num.sc <- scale.f(logReturn.hsi.num)
```


# Simulation Study

The goal of this section is to study the performance of the heuristic algorithm of choosing group size in an idealized situation: the dataset is indeed generated in a equal-size blocking way. We will see whether the algorithm can detect the true block size from the data: if it does work, it means it is in the right direction to do the detection so that it can be extended later on. Otherwise, it means the method cannot capture the blocking feature correctly. 

## KS.test (attempts)

```{r}
#equal-block design with group size 200
set.seed(123)
N1 <- 2e3
gr.size1 <- 2e2
gr.num1 <- N1/gr.size1
n.seq1 <- seq(20, N1/4, 5)
z.ind1 <- sample(c(1,2,3), gr.num1, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

# re.ks.unif <- choose.gr.size(f.noise.gen = function(N){ 
#   noise.gen.eqblock(N, gr.size = gr.size1, sd.set = c(0.5, 1, 2), 
#                     z.ind = z.ind1)
#   }, 
#   f.obj = function(dat) f.ks.unif(dat, gr.f = function(x) mean(x)), 
#   N = N1, rep.time = 50, n.seq = n.seq1, 
#   f.trans = function(x) x^2, save.ind = TRUE, name.char = "ks-unif-novlp1",
#   print.re.ind = FALSE, ylab = "D/sqrt(num.gr)")

#f.ks.unif: test statistic/sqrt(num.gr)

re.ks.unif <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size1, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind1)
  }, 
  f.obj = function(dat) f.ks.unif(dat, gr.f = function(x) sqrt(mean(x))), 
  N = N1, rep.time = 50, n.seq = n.seq1, 
  f.trans = function(x) x^2, save.ind = TRUE, name.char = "ks-unif-novlp1",
  print.re.ind = FALSE, ylab = "D/sqrt(num.gr)")

#check overlapping group if needed

```

The possible concerns on the KS.test can be found in (Notes-choose-gr-size.pdf). 

## AIC criterion

### Equal-block piecewise constant sigma 

```{r}
#equal-block design with group size 200
set.seed(123)
N1 <- 2e3
gr.size1 <- 2e2
gr.num1 <- N1/gr.size1
n.seq1 <- seq(20, N1/4, 5)
z.ind1 <- sample(c(1,2,3), gr.num1, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.AIC1 <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size1, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind1)
  }, 
  f.obj = function(dat){f.AIC(dat, short.ind = FALSE)}, 
  N = N1, rep.time = 1e2, n.seq = n.seq1, 
  f.trans = function(x) x, name.char = "AICfull-200", save.ind = TRUE, 
  ylab = "centered AIC")
#save.ind = TRUE, it will save an image file on the current directory
#it does not work very well compared with BIC
```

```{r}
set.seed(123)
N2 <- 2e3
gr.size2 <- 250
gr.num2 <- N2/gr.size2
n.seq2 <- seq(20, N2/4, 5)
z.ind2 <- sample(c(1,2,3), gr.num2, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.AIC2 <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size2, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind2)
  }, f.obj = f.AIC, N = N2, rep.time = 1e2, n.seq = n.seq2, 
  f.trans = function(x) x, save.ind = TRUE, name.char = "AICfull-250", 
  ylab = "centered AIC")
```
(also check it on real dataset if needed.)

## BIC criterion

### Equal-block piecewise constant sigma 

```{r}
#equal-block design with group size 200
set.seed(123)
N1 <- 2e3
gr.size1 <- 2e2
gr.num1 <- N1/gr.size1
n.seq1 <- seq(20, N1/4, 5)
z.ind1 <- sample(c(1,2,3), gr.num1, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.BIC1 <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size1, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind1)
  }, 
  f.obj = function(dat){f.BIC(dat, short.ind = FALSE)}, 
  N = N1, rep.time = 1e2, n.seq = n.seq1, 
  f.trans = function(x) x, name.char = "BICfull-200", save.ind = TRUE)
#save.ind = TRUE, it will save an image file on the current directory
```

```{r}
set.seed(123)
N2 <- 2e3
gr.size2 <- 250
gr.num2 <- N2/gr.size2
n.seq2 <- seq(20, N2/4, 5)
z.ind2 <- sample(c(1,2,3), gr.num2, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.BIC2 <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size2, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind2)
  }, f.obj = f.BIC, N = N2, rep.time = 1e2, n.seq = n.seq2, 
  f.trans = function(x) x, save.ind = TRUE, name.char = "BICfull-250")
```

```{r}
set.seed(123)
N2 <- 2e3
gr.size2 <- 100
gr.num2 <- N2/gr.size2
n.seq2 <- seq(20, N2/4, 5)
z.ind2 <- sample(c(1,2,3), gr.num2, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.BIC3 <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size2, sd.set = c(0.5, 1, 2), 
                    z.ind = z.ind2)
  }, f.obj = f.BIC, N = N2, rep.time = 1e2, n.seq = n.seq2, 
  f.trans = function(x) x, save.ind = TRUE, name.char = "BICfull-100")
```

### Equal-block piecewise constant sigma (random)

```{r}
#the sigma in each block is random
set.seed(123)
N2 <- 2e3
gr.size2 <- 250
gr.num2 <- N2/gr.size2
n.seq2 <- seq(20, N2/4, 5)
#z.ind2 <- sample(c(1,2,3), gr.num2, replace = TRUE, prob = c(3,2,1)/5)
#plot(z.ind1, type = "l")

re.BIC2.rand <- choose.gr.size(f.noise.gen = function(N){ 
  noise.gen.eqblock(N, gr.size = gr.size2, sd.set = c(0.5, 1, 2), 
                    z.ind = NULL)
  }, f.obj = f.BIC, N = N2, rep.time = 1e2, n.seq = n.seq2, 
  f.trans = function(x) x, save.ind = TRUE, name.char = "BICfull-250-rand")
```

```{r}
#hist(re.BIC2.rand$n.opt.seq)
#abline(v=gr.size2, col=2)
```

### Unequal-block 

(Check the behavior of this method on unequal group size.)

```{r}
#testuncertainty 
N2 <- 2e3
gr.size2 <- 250
gr.num2 <- N2/gr.size2
n.seq2 <- seq(50, N2/4, 5)

x.re <- rsemiGnorm(N2, gr.len.mean = gr.size2, rmaximal.k = rmaximal)
w.seq <- x.re$w.seq
plot(w.seq, type = "l")
re.tku <- testUncertainty(w.seq, moment.num = 2, n.check = 200, n.max.prop = 1/4, n.step = 10, smooth.plot.test = TRUE)
```

```{r}
set.seed(123)

#check rmaximal
#unequal group size
re.BIC2.rand <- choose.gr.size(f.noise.gen = function(N){ 
  x <- rsemiGnorm(N, gr.len.mean = gr.size2, rmaximal.k = rmaximal)
  x$w.seq
  }, f.obj = f.BIC, N = N2, rep.time = 1e2, n.seq = n.seq2, 
  f.trans = function(x) x, save.ind = TRUE, name.char = "BICfull-250-uneq", 
  center.val.mat = TRUE) 
#center.val.mat = TRUE
#for better visualization
```

```{r}
hist(re.BIC2.rand$n.opt.seq, breaks = "scott")
abline(v = gr.size2, col=2)
```

### Simulated SV

(related to the discussion notes on Gframe-TS)

#### Setup 

```{r setup}
N1 <- 2e3
n.seq1 <- seq(5, N1/4, 10)
set.seed(123)
```

#### No leverage

```{r}
#no leverage
#re <- ar1.gen.sigdepn.noblock(N1, rho = -0.6, phi = 0.8, sig = 0.17, b.sc = 1.2)
re <- ar1.gen.sigdepn.noblock(N1, bounded.var = FALSE, plot.ind = FALSE, 
                          b.sc = 0.2, rho = 0, b.true = 0.7, phi = 0.5)
sim.seq <- re$w.seq
plot(sim.seq, type = "l")


re <- choose.gr.size.onepath(sim.seq, 
                             n.seq = n.seq1, 
                             f.obj = f.BIC, 
                             f.trans = function(x) x)
re$n.opt
```

```{r}
re.BIC.sv1 <- choose.gr.size(f.noise.gen = function(N){ 
  x <- ar1.gen.sigdepn.noblock(N1, bounded.var = FALSE, plot.ind = FALSE, 
                          b.sc = 0.2, rho = 0, b.true = 0.7, phi = 0.5)
  x$w.seq
  }, f.obj = f.BIC, N = N1, rep.time = 1e2, n.seq = n.seq1, 
  f.trans = function(x) x, save.ind = FALSE, name.char = "BIC-sv", 
  center.val.mat = TRUE) 
```

```{r}
hist(re.BIC.sv1$n.opt.seq)
#use an adaptive choice of group sizes (adapt to the current data sequence)
```


#### With leverage

```{r}
N1 <- 2e3
n.seq1 <- seq(5, N1/4, 10)
set.seed(123)
#re <- ar1.gen.sigdepn.noblock(N1, rho = -0.6, phi = 0.8, sig = 0.17, b.sc = 1.2)
re <- ar1.gen.sigdepn.noblock(N1, bounded.var = FALSE, plot.ind = FALSE, 
                          b.sc = 0.2, rho = -0.6, b.true = 0.7, phi = 0.5)
sim.seq <- re$w.seq
plot(sim.seq, type = "l")


re <- choose.gr.size.onepath(sim.seq, 
                             n.seq = n.seq1, 
                             f.obj = f.BIC, 
                             f.trans = function(x) x)
re$n.opt
```

```{r}
re.BIC.sv2 <- choose.gr.size(f.noise.gen = function(N){ 
  x <- ar1.gen.sigdepn.noblock(N1, bounded.var = FALSE, plot.ind = FALSE, 
                          b.sc = 0.2, rho = -0.6, b.true = 0.7, phi = 0.5)
  x$w.seq
  }, f.obj = f.BIC, N = N1, rep.time = 1e2, n.seq = n.seq1, 
  f.trans = function(x) x, save.ind = FALSE, name.char = "BIC-sv", 
  center.val.mat = TRUE) 
```

```{r}
hist(re.BIC.sv2$n.opt.seq, breaks = "scott")
```

## Change-point detection 

# Simulated GARCH 

(also check GARCH(1,1))

# Real-world dataset 

```{r}
N1 <- 5e3
lr.seq <- logReturn.gspc.num.sc
lr.seq1 <- lr.seq[seq_len(N1)]
```


## Test of uncertainty 

```{r}
plot(lr.seq1, type = "l")
```

```{r}
re <- testUncertainty(lr.seq1, varphi = function(x) x^2, hist.bin = 60)
#collect the points from smooth curve, then draw a histogram
#also perform the test based on the smoothed values 
```

```{r}
#check the distance to uniform 
#relative entropy
```

## KS.test (attempts)

```{r}
n.seq1 <- seq(10, 500, 5)

re <- choose.gr.size.onepath(lr.seq1, 
                             n.seq = n.seq1, 
                             f.obj = function(dat) {
                               f.ks.unif(dat, gr.f = function(x) sqrt(mean(x)))
                               }, 
                             f.trans = function(x) x^2)
re$n.opt
#some of the values cannot show up (one reason is the rounding p-value is recorded as 0.)
```

Another important issue here is the test tends to show insignificance (or accept the null) as the number of measurements ($N/n$) decreases. This is reason why we have 
$$
V(n) = -\ln p_n,
$$
decreases as $n$ increases. 

## BIC criterion

#### One path

```{r}
#check log return 
re <- choose.gr.size.onepath(lr.seq1, 
                             n.seq = n.seq1, f.obj = f.BIC, 
                             f.trans = function(x) x, save.ind = TRUE, 
                             name.char = "BIC-gspc")
re$n.opt
```

```{r}
max.mean(lr.seq1^2, n.guess = re$n.opt) #estimation of the sigma interval
```

#### Random start date

```{r}
set.seed(123)
re.gspc <- choose.gr.size(f.noise.gen = function(N){
  start.ind <- sample((1:2e2)*10, 1)
  logReturn.gspc.num.sc[start.ind + seq_len(N)]
}, N = N1, f.obj = function(dat) f.BIC(dat, short.ind = FALSE), 
n.seq = n.seq1, rep.time = 1e2, 
save.ind = TRUE, name.char = "BIC-center-gspc", 
f.trans = function(x) x, 
print.re.ind = TRUE, center.val.mat = TRUE)
#center.val.mat = TRUE
#to remove the different basic level of BIC, so as to better visualize
#The suggested group size for SP500 is 140 (sd: 42). 

#when big N change, the suggested group size will change, 

#different periods, 
#
#it will change to different group size 
#W=2e3 

#average of the group size 

#historical window size, 

#calibration 

#G-VaR formula

#uniform distribution 

#normalized

```

uniform distribution,

normalized distance, 

evenly spread, 

(sqrt(m))


```{r}
hist(re.gspc$n.opt.seq)
```

```{r}
#also try it on a different index 
lr.seq2 <- logReturn.hsi.num.sc[seq_len(N1)]
#plot(lr.seq2, type = "l")
#matplot(cbind(lr.seq1,lr.seq2), type = "l")

re <- choose.gr.size.onepath(lr.seq2, 
                             n.seq = n.seq1, f.obj = f.BIC, 
                             save.ind = TRUE, name.char = "BIC-hsi")
#also around 25
re$n.opt
```

```{r}
set.seed(123)
re.hsi <- choose.gr.size(f.noise.gen = function(N){
  start.ind <- sample((1:2e2)*10, 1)
  logReturn.hsi.num.sc[start.ind + seq_len(N)]
}, N = N1, f.obj = function(dat) f.BIC(dat, short.ind = FALSE), 
n.seq = n.seq1, rep.time = 1e2, 
save.ind = TRUE, name.char = "BIC-center-hsi", 
f.trans = function(x) x, center.val.mat = TRUE)

#The suggested group size for HSI is 127 (sd: 42 ). 
```

```{r}
hist(re.hsi$n.opt.seq)
```

### Blocking bootstrap

(related to Gframe-TS: robust-CI-coverage-comp)

```{r}
N1 <- 2e3
n.seq1 <- seq(5, N1/4, 10)
set.seed(123)
```

```{r}
re.gspc <- choose.gr.size(f.noise.gen = function(N){
  w.seq.real <- boot.mov.block(N.boot = N, block.size = 2e2, step = 50, 
                               dat.seq = logReturn.gspc.num.sc)
  w.seq.real
}, N = N1, f.obj = function(dat) f.BIC(dat, short.ind = FALSE), 
n.seq = n.seq1, rep.time = 1e2, 
save.ind = TRUE, name.char = "BIC-boostrap-gspc", 
f.trans = function(x) x, center.val.mat = TRUE)
```

```{r}
hist(re.gspc$n.opt.seq)
```

